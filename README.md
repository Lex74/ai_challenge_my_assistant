# AI Challenge My Assistant

Набор CLI-инструментов для работы с локальными LLM-моделями через Ollama.

## Компоненты

### 1. Personal Agent (`personal_agent.py`)

Персональный AI-агент с долговременной памятью. Запоминает всё о пользователе и использует эту информацию в диалогах.

**Возможности:**
- Долговременная память о пользователе (профиль, факты, интересы, цели)
- Автоматическое извлечение новой информации из диалогов
- Поиск по сохранённым фактам
- Экспорт/импорт памяти
- Логирование всех диалогов

**Команды:**
```
/memory          - показать всё, что агент знает о вас
/search <query>  - поиск в памяти
/fact <факт>     - добавить факт вручную
/set <поле> <значение> - установить поле профиля (имя, возраст, город, работа, ник)
/clear           - очистить историю текущего разговора
/exit            - выход
```

**Использование:**
```bash
python personal_agent.py [-m MODEL] [--show-memory] [--export-memory FILE] [--import-memory FILE]
```

### 2. Voice Agent (`voice_agent.py`)

Голосовой AI-агент с распознаванием речи. Преобразует голосовые команды в текст и отправляет их в LLM для получения ответа.

**Возможности:**
- Распознавание речи с микрофона (русский язык)
- Интеграция с Personal Agent (использует память о пользователе)
- Текстовый вывод ответов от LLM
- Режим тестирования на стандартных запросах

**Использование:**
```bash
# Интерактивный голосовой режим
python voice_agent.py [-m MODEL] [--language LANG]

# Тестирование на стандартных запросах
python voice_agent.py --test [-m MODEL]

# Тестирование с кастомными запросами
python voice_agent.py --test --queries "посчитай 2+2" "дай определение"

# Быстрое тестирование без микрофона (текстовый режим)
python test_voice_agent.py [MODEL]
```

**Примеры тестовых запросов:**
- "посчитай 25 умножить на 17"
- "дай определение искусственного интеллекта"
- "скажи анекдот"

**Требования:**
- Микрофон (для голосового режима)
- Интернет-соединение (для Google Speech Recognition API)
- Установленные зависимости: `speechrecognition`, `pyaudio`

## Установка

### Требования
- Python 3.9+
- Установленный Ollama: https://ollama.ai

### Установка зависимостей
```bash
pip install -r requirements.txt
```

**Примечание для macOS:**
Если возникают проблемы с установкой `pyaudio`, может потребоваться:
```bash
brew install portaudio
pip install pyaudio
```

**Примечание для Linux:**
Может потребоваться установить системные зависимости:
```bash
sudo apt-get install portaudio19-dev python3-pyaudio
# или для Fedora/CentOS:
sudo yum install portaudio-devel
```

### Запуск Ollama
```bash
ollama serve
```

### Рекомендуемые модели
```bash
ollama pull qwen2.5:7b
```

## Переменные окружения

| Переменная | Описание | По умолчанию |
|------------|----------|--------------|
| `OLLAMA_API_URL` | URL Ollama API | `http://127.0.0.1:11434` |
| `OLLAMA_TEMPERATURE` | Температура модели | `0.7` |
| `OLLAMA_MAX_TOKENS` | Макс. токенов в ответе | `4096` |
| `OLLAMA_CONTEXT_WINDOW` | Размер контекстного окна | `8192` |

## Хранение данных

**Personal Agent** хранит данные в `~/.personal_agent/`:
- `memory.json` - долговременная память
- `conversations/` - логи диалогов

## Лицензия

MIT
