# AI Challenge My Assistant

Набор CLI-инструментов для работы с локальными LLM-моделями через Ollama.

## Компоненты

### 1. Personal Agent (`personal_agent.py`)

Персональный AI-агент с долговременной памятью. Запоминает всё о пользователе и использует эту информацию в диалогах.

**Возможности:**
- Долговременная память о пользователе (профиль, факты, интересы, цели)
- Автоматическое извлечение новой информации из диалогов
- Поиск по сохранённым фактам
- Экспорт/импорт памяти
- Логирование всех диалогов

**Команды:**
```
/memory          - показать всё, что агент знает о вас
/search <query>  - поиск в памяти
/fact <факт>     - добавить факт вручную
/set <поле> <значение> - установить поле профиля (имя, возраст, город, работа, ник)
/clear           - очистить историю текущего разговора
/exit            - выход
```

**Использование:**
```bash
python personal_agent.py [-m MODEL] [--show-memory] [--export-memory FILE] [--import-memory FILE]
```

### 2. Ollama CLI (`ollama_cli.py`)

CLI агент для работы с моделями Ollama. Настроен для обучения iOS разработке на Swift.

**Возможности:**
- Интерактивный чат с моделями
- Аналитика JSON данных в терминале
- Естественно-языковые запросы к данным
- ASCII-визуализация данных

**Команды чата:**
```
/help            - справка
/models          - список доступных моделей
/switch <model>  - переключить модель
/clear           - очистить историю диалога
/history         - показать историю диалога
/exit            - выход
```

**Аналитика данных:**
```
/load <file> [name]    - загрузить JSON файл
/data                  - показать загруженные данные
/schema [name]         - показать структуру данных
/stats [name]          - статистика по данным
/analyze <question>    - задать аналитический вопрос
/chart <bar> <column>  - построить график
/unload <name>         - выгрузить данные
```

**Использование:**
```bash
python ollama_cli.py [-m MODEL] [-p PROMPT] [--list-models] [--temperature T] [--max-tokens N] [--context-window N]
```

## Установка

### Требования
- Python 3.9+
- Установленный Ollama: https://ollama.ai

### Установка зависимостей
```bash
pip install -r requirements.txt
```

### Запуск Ollama
```bash
ollama serve
```

### Рекомендуемые модели
```bash
ollama pull qwen2.5:7b
```

## Переменные окружения

| Переменная | Описание | По умолчанию |
|------------|----------|--------------|
| `OLLAMA_API_URL` | URL Ollama API | `http://127.0.0.1:11434` |
| `OLLAMA_TEMPERATURE` | Температура модели | `0.7` |
| `OLLAMA_MAX_TOKENS` | Макс. токенов в ответе | `4096` |
| `OLLAMA_CONTEXT_WINDOW` | Размер контекстного окна | `8192` |

## Хранение данных

**Personal Agent** хранит данные в `~/.personal_agent/`:
- `memory.json` - долговременная память
- `conversations/` - логи диалогов

## Лицензия

MIT
